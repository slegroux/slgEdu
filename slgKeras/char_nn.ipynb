{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theano\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import sys\n",
    "from keras import backend as K\n",
    "print K.backend()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('corpus length:', 600901)\n"
     ]
    }
   ],
   "source": [
    "path = get_file('nietzsche.txt', origin=\"https://s3.amazonaws.com/text-datasets/nietzsche.txt\")\n",
    "text = open(path).read()\n",
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('total unique chars:', 86)\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)+1\n",
    "print('total unique chars:', vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n !\"\\'(),-.0123456789:;=?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]_abcdefghijklmnopqrstuvwxyz'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars.insert(0, \"\\0\")\n",
    "''.join(chars[1:-6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\x00', '\\n', ' ', '!', '\"']\n",
      "PREFACE\n",
      "\n",
      "\n",
      "SUPPOSING that Truth is a woman--what th\n"
     ]
    }
   ],
   "source": [
    "print chars[:5]\n",
    "print text[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cannot model characters directly and convert characters to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "char2indices = dict((c,i) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('-', 1)\n"
     ]
    }
   ],
   "source": [
    "print (chars[9], char2indices['\\n'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFACE\n",
      "\n",
      "\n",
      "\n",
      "[40, 42, 29, 30, 25, 27, 29, 1, 1, 1]\n",
      "['P', 'R', 'E', 'F', 'A', 'C', 'E', '\\n', '\\n', '\\n']\n"
     ]
    }
   ],
   "source": [
    "print text[:10]\n",
    "\n",
    "test = [char2indices[c] for c in text[:10]]\n",
    "print test\n",
    "print [chars[c] for c in test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_text = [char2indices[c] for c in text[:]]\n",
    "input_length = 100\n",
    "X = []\n",
    "y = []\n",
    "for i in range(0, len(sub_text) - input_length):\n",
    "    X.append(sub_text[i:i+input_length])\n",
    "    y.append(sub_text[i+input_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600801"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([40, 42, 29, 30, 25, 27, 29, 1, 1, 1, 43, 45, 40, 40, 39, 43, 33, 38, 31, 2, 73, 61, 54, 73, 2, 44, 71, 74, 73, 61, 2, 62, 72, 2, 54, 2, 76, 68, 66, 54, 67, 9, 9, 76, 61, 54, 73, 2, 73, 61, 58, 67, 24, 2, 33, 72, 2, 73, 61, 58, 71, 58, 2, 67, 68, 73, 2, 60, 71, 68, 74, 67, 57, 1, 59, 68, 71, 2, 72, 74, 72, 69, 58, 56, 73, 62, 67, 60, 2, 73, 61, 54, 73, 2, 54, 65, 65, 2, 69, 61], 62)\n",
      "([42, 29, 30, 25, 27, 29, 1, 1, 1, 43, 45, 40, 40, 39, 43, 33, 38, 31, 2, 73, 61, 54, 73, 2, 44, 71, 74, 73, 61, 2, 62, 72, 2, 54, 2, 76, 68, 66, 54, 67, 9, 9, 76, 61, 54, 73, 2, 73, 61, 58, 67, 24, 2, 33, 72, 2, 73, 61, 58, 71, 58, 2, 67, 68, 73, 2, 60, 71, 68, 74, 67, 57, 1, 59, 68, 71, 2, 72, 74, 72, 69, 58, 56, 73, 62, 67, 60, 2, 73, 61, 54, 73, 2, 54, 65, 65, 2, 69, 61, 62], 65)\n"
     ]
    }
   ],
   "source": [
    "print (X[0], y[0])\n",
    "print (X[1], y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(max(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = np.reshape(X, (len(X), input_length, 1))\n",
    "# normalize\n",
    "X = X / float(vocab_size)\n",
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((600801, 100, 1), (600801, 86))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 256\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define checkpoint: for long training save when improvement in loss\n",
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "600704/600801 [============================>.] - ETA: 1s - loss: 2.9326Epoch 00000: loss improved from inf to 2.93258, saving model to weights-improvement-00-2.9326.hdf5\n",
      "600801/600801 [==============================] - 7517s - loss: 2.9326  \n",
      "Epoch 2/2\n",
      "600704/600801 [============================>.] - ETA: 1s - loss: 2.7955Epoch 00001: loss improved from 2.93258 to 2.79546, saving model to weights-improvement-01-2.7955.hdf5\n",
      "600801/600801 [==============================] - 6237s - loss: 2.7955  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1159611d0>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=1, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"weights-improvement-01-2.7955.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1)\n",
      "Seed:\n",
      "\" ot\n",
      "cone to the hmportance of relhghon, of thhs there can be no coubt. It hs\n",
      "also equally certahn tha \"\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n",
      "h\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# randomly pick initial sequence among input\n",
    "start = np.random.randint(0, len(X)-1)\n",
    "pattern = X[start] * vocab_size\n",
    "print pattern.shape\n",
    "print \"Seed:\"\n",
    "print \"\\\"\", ''.join([chars[int(c)] for c in pattern]),\"\\\"\"\n",
    "# generate characters\n",
    "for i in range(100):\n",
    "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "#     print \"x: \", x.shape\n",
    "#     x = x / float(n_vocab)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = np.argmax(prediction)\n",
    "    result = chars[index]\n",
    "    seq_in = [chars[int(value)] for value in pattern]\n",
    "    sys.stdout.write(result)\n",
    "    pattern = np.append(pattern,index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "#     print \"shape: \", pattern.shape\n",
    "    print \"\\nDone.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1)\n",
      "(1, 100, 1)\n",
      "s\n",
      "['s', ' ', 'f', 'r', 'o', 'm', ' ', 'm', 'e', 't', 'a', 'p', 'h', 'y', 's', 'h', 'c', ' ', 'a', 'n', 'c', ' ', 'l', 'o', 'o', 'k', ' ', 'b', 'a', 'c', 'k', ' ', 'a', 't', ' ', 'h', 't', ' ', 'w', 'h', 't', 'h', '\\n', 'a', 'n', ' ', 'a', 'h', 'r', ' ', 'o', 'f', ' ', 's', 'u', 'p', 'e', 'r', 'h', 'o', 'r', 'h', 't', 'y', ':', ' ', 'w', 'h', 'e', 'r', 'e', 'a', 's', ' ', 'h', 'e', 'r', 'e', ',', ' ', 'n', 'o', ' ', 'l', 'e', 's', 's', ' ', 't', 'h', 'a', 'n', ' ', 'h', 'n', ' ', 't', 'h', 'e', ' ']\n"
     ]
    }
   ],
   "source": [
    "print pattern.shape\n",
    "print x.shape\n",
    "prediction = model.predict(x, verbose=0)\n",
    "index = np.argmax(prediction)\n",
    "print chars[index]\n",
    "print [chars[int(value*vocab_size)] for value in pattern]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
